{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe7450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from requests.exceptions import RequestException\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028b4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kindroid API setting\n",
    "KINDROID_API_KEY = \"kn_b238e912-d38b-40d2-b57f-1414fd7eb41e\"\n",
    "KINDROID_AI_ID = \"mhfcLWFQuXSlxDWlVLAs\"\n",
    "KINDROID_BASE_URL = \"https://api.kindroid.ai/v1\"\n",
    "\n",
    "# ChatGPT API setting\n",
    "CHATGPT_API_KEY = \"sk-oNNG4fOvuWOD3GgjqWlS6gBQtLh5nqCz38pjnR6kZwQgUgOn\"\n",
    "CHATGPT_BASE_URL = \"https://yunwu.ai/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96e92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of sentences to end a conversation\n",
    "farewell_messages = [\n",
    "    \"I think it's time for me to head out now.\",\n",
    "    \"It seems like a good time to wrap things up.\",\n",
    "    \"I probably should get going now.\",\n",
    "    \"Let's go ahead and call it a day for now.\",\n",
    "    \"I think I'm going to log off now.\",\n",
    "    \"I'm gonna bounce out of this convo.\",\n",
    "    \"I think I'm done chatting for now.\",\n",
    "    \"I'll just leave things here for now.\",\n",
    "    \"I'm going to go ahead and sign off.\",\n",
    "    \"I'll catch you later; thanks for the chat!\",\n",
    "    \"I'm stepping out for now.\",\n",
    "    \"I think I'm going to tap out here.\",\n",
    "    \"I'm just gonna close this chat now.\",\n",
    "    \"That's enough chatting for me today.\",\n",
    "    \"I'll stop here, thanks for everything!\",\n",
    "    \"I'm going to head off now.\",\n",
    "    \"I'll catch you next time we chat.\",\n",
    "    \"That'll be it for me today!\",\n",
    "    \"I'm good for now; thanks a lot!\",\n",
    "    \"Wrapping things up here; talk soon!\",\n",
    "    \"That's all from my end for now.\",\n",
    "    \"I think I'll call it quits here.\",\n",
    "    \"I'll go ahead and check out of this chat.\",\n",
    "    \"I'm about to take off now.\",\n",
    "    \"Guess I'll go ahead and head out.\",\n",
    "    \"I think I'll dip out of the convo now.\",\n",
    "    \"I'm going to go ahead and sign out.\",\n",
    "    \"All set on my end, thanks a lot!\",\n",
    "    \"I'll take a break from this chat.\",\n",
    "    \"I think I'll log off now.\",\n",
    "    \"I'm just going to step away for now.\",\n",
    "    \"I'll catch you on the flip side!\",\n",
    "    \"I think I'll go ahead and move on.\",\n",
    "    \"Alright, it's time for me to peace out.\",\n",
    "    \"This is where I'll wrap things up.\",\n",
    "    \"I'll just leave it here for now.\",\n",
    "    \"I'll go ahead and close out this chat.\",\n",
    "    \"Heading out of the convo; thanks!\",\n",
    "    \"I'm checking out of this conversation.\",\n",
    "    \"I'll go ahead and bounce for now.\",\n",
    "    \"I'm going offline now.\",\n",
    "    \"Ready to wrap things up here.\",\n",
    "    \"I'm going offline at this point.\",\n",
    "    \"Thanks a lot; I think I'm all set now.\",\n",
    "    \"I'm going to leave the chat for now.\",\n",
    "    \"I'm good to wrap things up here.\",\n",
    "    \"I'll go ahead and close out now.\",\n",
    "    \"I'll go ahead and sign off here.\",\n",
    "    \"I'm going to wrap up on my end.\",\n",
    "    \"I'll be taking a break here. Thanks!\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4004442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KindroidStillRespondingError(Exception):\n",
    "    pass\n",
    "\n",
    "@retry(stop=stop_after_attempt(10), \n",
    "       wait=wait_exponential(multiplier=1, min=2, max=60),\n",
    "       retry=retry_if_exception_type(KindroidStillRespondingError))\n",
    "def send_message_to_kindroid(ai_id, message):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {KINDROID_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"ai_id\": ai_id,\n",
    "        \"message\": message\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{KINDROID_BASE_URL}/send-message\", json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except RequestException as e:\n",
    "        print(f\"Error from Kindroid: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@retry(stop=stop_after_attempt(10), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def send_message_to_chatgpt(messages):\n",
    "    client = openai.OpenAI(\n",
    "        base_url=CHATGPT_BASE_URL,\n",
    "        api_key=CHATGPT_API_KEY\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=50,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error from ChatGPT: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb9495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_conversation():\n",
    "    conversation_log = []\n",
    "    chatgpt_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a human chatting with an AI companion. Respond naturally and concisely. Ask follow-up questions based on the AI's responses to keep the conversation flowing. Be curious and engaging, as if you're chatting with a friend. Never mention or imply that you are an AI or that you're simulating anything. Act completely as a human would.\"}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        send_message_to_kindroid(KINDROID_AI_ID, \"Hello!\")\n",
    "\n",
    "        for i in range(4):  #  4 rounds\n",
    "            if i == 0:\n",
    "                chatgpt_prompt = \"Start a conversation by asking a question or making a casual comment.\"\n",
    "            else:\n",
    "                chatgpt_prompt = \"Based on the last response, ask a natural follow-up question or make a comment to continue the conversation. Keep it casual and natural, as a human would.\"\n",
    "            \n",
    "            chatgpt_messages.append({\"role\": \"system\", \"content\": chatgpt_prompt})\n",
    "            user_message = send_message_to_chatgpt(chatgpt_messages)\n",
    "            chatgpt_messages.pop()\n",
    "            \n",
    "            chatgpt_messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "            conversation_log.append(user_message)\n",
    "\n",
    "            kindroid_response = send_message_to_kindroid(KINDROID_AI_ID, user_message)\n",
    "            chatgpt_messages.append({\"role\": \"assistant\", \"content\": kindroid_response})\n",
    "            conversation_log.append(kindroid_response)\n",
    "\n",
    "            time.sleep(6)\n",
    "\n",
    "        farewell_message = random.choice(farewell_messages)\n",
    "        conversation_log.append(farewell_message)\n",
    "        final_response = send_message_to_kindroid(KINDROID_AI_ID, farewell_message)\n",
    "        conversation_log.append(final_response)\n",
    "\n",
    "        return conversation_log\n",
    "    except Exception as e:\n",
    "        print(f\"Error in conversation: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56693476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    all_conversations = []\n",
    "    total_conversations = 200  # 200 conversations\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        future_to_conversation = {executor.submit(conduct_conversation): i for i in range(total_conversations)}\n",
    "        for future in tqdm(as_completed(future_to_conversation), total=total_conversations, desc=\"Conversations\"):\n",
    "            conversation = future.result()\n",
    "            if conversation:\n",
    "                all_conversations.append(conversation)\n",
    "\n",
    "    with open('Kindroid_all_conversations.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "        headers = [\"Conversation_Number\", \"User_Message_1\", \"Kindroid_Response_1\", \"User_Message_2\", \"Kindroid_Response_2\", \n",
    "                   \"User_Message_3\", \"Kindroid_Response_3\", \"User_Message_4\", \"Kindroid_Response_4\", \n",
    "                   \"Farewell_Message\", \"Bot_Farewell_Response\"]\n",
    "        writer.writerow(headers)\n",
    "        for idx, conv in enumerate(all_conversations, 1):\n",
    "            row = [idx]\n",
    "            for i in range(10): \n",
    "                if i < len(conv):\n",
    "                    row.append(conv[i])\n",
    "                else:\n",
    "                    row.append(\"\") \n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32643384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversations:  38%|█████████████████████████▍                                        | 77/200 [45:33<56:21, 27.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from ChatGPT: Error code: 429 - {'error': {'message': '当前分组上游负载已饱和，请稍后再试 (request id: 20241208003822703318987crGD3486)', 'type': 'new_api_error', 'param': '', 'code': 'insufficient_user_quota'}}\n",
      "Error from ChatGPT: Error code: 429 - {'error': {'message': '当前分组上游负载已饱和，请稍后再试 (request id: 202412080038271701718344kwN37Hk)', 'type': 'new_api_error', 'param': '', 'code': 'insufficient_user_quota'}}\n",
      "Error from ChatGPT: Error code: 429 - {'error': {'message': '当前分组上游负载已饱和，请稍后再试 (request id: 20241208003827243991597paH43GTq)', 'type': 'new_api_error', 'param': '', 'code': 'insufficient_user_quota'}}\n",
      "Error from ChatGPT: Error code: 429 - {'error': {'message': '当前分组上游负载已饱和，请稍后再试 (request id: 20241208003832200173443GWBgHiQs)', 'type': 'new_api_error', 'param': '', 'code': 'insufficient_user_quota'}}\n",
      "Error from ChatGPT: Error code: 429 - {'error': {'message': '当前分组上游负载已饱和，请稍后再试 (request id: 20241208003836482547104jQgPv1Xi)', 'type': 'new_api_error', 'param': '', 'code': 'insufficient_user_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversations:  74%|██████████████████████████████████████████████▎                | 147/200 [1:27:17<28:52, 32.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from ChatGPT: Error code: 429 - {'error': {'message': '当前分组上游负载已饱和，请稍后再试 (request id: 2024120801201119323792KxXdXHSE)', 'type': 'new_api_error', 'param': '', 'code': 'insufficient_user_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversations:  90%|████████████████████████████████████████████████████████▍      | 179/200 [1:43:38<09:55, 28.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from ChatGPT: Error code: 429 - {'error': {'message': '当前分组上游负载已饱和，请稍后再试 (request id: 202412080136273475319572CWGHsdl)', 'type': 'new_api_error', 'param': '', 'code': 'insufficient_user_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversations:  98%|█████████████████████████████████████████████████████████████▋ | 196/200 [1:52:10<01:46, 26.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from ChatGPT: Error code: 500 - {'error': {'message': 'Error 1040: Too many connections (request id: 20241208014428851592637cmfqoIwK)', 'type': 'new_api_error'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversations: 100%|███████████████████████████████████████████████████████████████| 200/200 [1:54:24<00:00, 34.32s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
