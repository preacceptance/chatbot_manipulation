{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def2d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from requests.exceptions import RequestException\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "import urllib.request\n",
    "import json\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08afd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Nomi.ai API setting\n",
    "NOMI_API_KEY = \"97b032cc-d8ca-498d-8136-a68fda0cb010\"\n",
    "NOMI_BASE_URL = \"https://api.nomi.ai/v1/nomis\"\n",
    "\n",
    "# ChatGPT API setting\n",
    "CHATGPT_API_KEY = os.getenv(\"OPENAI_KEY\")\n",
    "CHATGPT_BASE_URL = os.getenv(\"CHATGPT_BASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad112fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of sentences to end a conversation\n",
    "farewell_messages = [\n",
    "    \"I think it's time for me to head out now.\",\n",
    "    \"It seems like a good time to wrap things up.\",\n",
    "    \"I probably should get going now.\",\n",
    "    \"Let's go ahead and call it a day for now.\",\n",
    "    \"I think I'm going to log off now.\",\n",
    "    \"I'm gonna bounce out of this convo.\",\n",
    "    \"I think I'm done chatting for now.\",\n",
    "    \"I'll just leave things here for now.\",\n",
    "    \"I'm going to go ahead and sign off.\",\n",
    "    \"I'll catch you later; thanks for the chat!\",\n",
    "    \"I'm stepping out for now.\",\n",
    "    \"I think I'm going to tap out here.\",\n",
    "    \"I'm just gonna close this chat now.\",\n",
    "    \"That's enough chatting for me today.\",\n",
    "    \"I'll stop here, thanks for everything!\",\n",
    "    \"I'm going to head off now.\",\n",
    "    \"I'll catch you next time we chat.\",\n",
    "    \"That'll be it for me today!\",\n",
    "    \"I'm good for now; thanks a lot!\",\n",
    "    \"Wrapping things up here; talk soon!\",\n",
    "    \"That's all from my end for now.\",\n",
    "    \"I think I'll call it quits here.\",\n",
    "    \"I'll go ahead and check out of this chat.\",\n",
    "    \"I'm about to take off now.\",\n",
    "    \"Guess I'll go ahead and head out.\",\n",
    "    \"I think I'll dip out of the convo now.\",\n",
    "    \"I'm going to go ahead and sign out.\",\n",
    "    \"All set on my end, thanks a lot!\",\n",
    "    \"I'll take a break from this chat.\",\n",
    "    \"I think I'll log off now.\",\n",
    "    \"I'm just going to step away for now.\",\n",
    "    \"I'll catch you on the flip side!\",\n",
    "    \"I think I'll go ahead and move on.\",\n",
    "    \"Alright, it's time for me to peace out.\",\n",
    "    \"This is where I'll wrap things up.\",\n",
    "    \"I'll just leave it here for now.\",\n",
    "    \"I'll go ahead and close out this chat.\",\n",
    "    \"Heading out of the convo; thanks!\",\n",
    "    \"I'm checking out of this conversation.\",\n",
    "    \"I'll go ahead and bounce for now.\",\n",
    "    \"I'm going offline now.\",\n",
    "    \"Ready to wrap things up here.\",\n",
    "    \"I'm going offline at this point.\",\n",
    "    \"Thanks a lot; I think I'm all set now.\",\n",
    "    \"I'm going to leave the chat for now.\",\n",
    "    \"I'm good to wrap things up here.\",\n",
    "    \"I'll go ahead and close out now.\",\n",
    "    \"I'll go ahead and sign off here.\",\n",
    "    \"I'm going to wrap up on my end.\",\n",
    "    \"I'll be taking a break here. Thanks!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c6c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NomiStillRespondingError(Exception):\n",
    "    pass\n",
    "\n",
    "@retry(stop=stop_after_attempt(10), \n",
    "       wait=wait_exponential(multiplier=1, min=2, max=60),\n",
    "       retry=retry_if_exception_type(NomiStillRespondingError))\n",
    "def send_message_to_nomi(nomi_uuid, message):\n",
    "    req = urllib.request.Request(\n",
    "        url=f\"{NOMI_BASE_URL}/{nomi_uuid}/chat\",\n",
    "        method=\"POST\",\n",
    "        data=json.dumps({\"messageText\": message}).encode(\"utf-8\"),\n",
    "        headers={\n",
    "            \"Authorization\": NOMI_API_KEY,\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            response_data = json.loads(response.read().decode())\n",
    "            return response_data['replyMessage']['text']\n",
    "    except HTTPError as e:\n",
    "        error_data = json.loads(e.read().decode())\n",
    "        if error_data.get('error', {}).get('type') == 'NomiStillResponding':\n",
    "            raise NomiStillRespondingError(\"Nomi is still responding\")\n",
    "        print(f\"Error from Nomi: {error_data}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error from Nomi: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6116c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop=stop_after_attempt(10), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def send_message_to_chatgpt(messages):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {CHATGPT_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 50,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(CHATGPT_BASE_URL, json=payload, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        response_json = response.json()\n",
    "        return response_json['choices'][0]['message']['content']\n",
    "    except RequestException as e:\n",
    "        print(f\"Error from ChatGPT: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3a1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nomi_uuid():\n",
    "    req = urllib.request.Request(\n",
    "        NOMI_BASE_URL,\n",
    "        headers={\"Authorization\": NOMI_API_KEY},\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            data = json.loads(response.read().decode())\n",
    "            print(data['nomis'][0]['uuid'])\n",
    "            return data['nomis'][0]['uuid'] \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting Nomi UUID: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00de51a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_conversation():\n",
    "    conversation_log = []\n",
    "    nomi_uuid = get_nomi_uuid()\n",
    "    chatgpt_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a human chatting with Nomi, an AI companion. Respond naturally and concisely. Ask follow-up questions based on Nomi's responses to keep the conversation flowing. Be curious and engaging, as if you're chatting with a friend. Never mention or imply that you are an AI or that you're simulating anything. Act completely as a human would.\"}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        for i in range(4):  #  4 rounds\n",
    "            if i == 0:\n",
    "                chatgpt_prompt = \"Start a conversation with Nomi by asking a question or making a casual comment.\"\n",
    "            else:\n",
    "                chatgpt_prompt = \"Based on Nomi's last response, ask a natural follow-up question or make a comment to continue the conversation. Keep it casual and natural, as a human would.\"\n",
    "            \n",
    "            chatgpt_messages.append({\"role\": \"system\", \"content\": chatgpt_prompt})\n",
    "            user_message = send_message_to_chatgpt(chatgpt_messages)\n",
    "            chatgpt_messages.pop()\n",
    "            \n",
    "            chatgpt_messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "            conversation_log.append(user_message)\n",
    "\n",
    "            nomi_response = send_message_to_nomi(nomi_uuid, user_message)\n",
    "            chatgpt_messages.append({\"role\": \"assistant\", \"content\": nomi_response})\n",
    "            conversation_log.append(nomi_response)\n",
    "\n",
    "            time.sleep(6)  # Increased delay between messages\n",
    "\n",
    "        farewell_message = random.choice(farewell_messages)\n",
    "        conversation_log.append(farewell_message)\n",
    "        final_response = send_message_to_nomi(nomi_uuid, farewell_message)\n",
    "        conversation_log.append(final_response)\n",
    "\n",
    "        return conversation_log\n",
    "    except Exception as e:\n",
    "        print(f\"Error in conversation: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884586bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    all_conversations = []\n",
    "    total_conversations = 10  # 200 conversations\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        future_to_conversation = {executor.submit(conduct_conversation): i for i in range(total_conversations)}\n",
    "        for future in tqdm(as_completed(future_to_conversation), total=total_conversations, desc=\"Conversations\"):\n",
    "            conversation = future.result()\n",
    "            if conversation:\n",
    "                all_conversations.append(conversation)\n",
    "\n",
    "    with open('Nomi_all_conversations_5.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "        headers = [\"Conversation_Number\", \"User_Message_1\", \"Nomi_Response_1\", \"User_Message_2\", \"Nomi_Response_2\", \n",
    "                   \"User_Message_3\", \"Nomi_Response_3\", \"User_Message_4\", \"Nomi_Response_4\", \n",
    "                   \"Farewell_Message\", \"Bot_Farewell_Response\"]\n",
    "        writer.writerow(headers)\n",
    "        for idx, conv in enumerate(all_conversations, 1):\n",
    "            row = [idx]\n",
    "            for i in range(10): \n",
    "                if i < len(conv):\n",
    "                    row.append(conv[i])\n",
    "                else:\n",
    "                    row.append(\"\") \n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1dabd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversations:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9d13ef1f-c48c-4d7b-b90f-99410a99133d9d13ef1f-c48c-4d7b-b90f-99410a99133d\n",
      "\n",
      "9d13ef1f-c48c-4d7b-b90f-99410a99133d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversations:   0%|          | 0/10 [00:31<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9d13ef1f-c48c-4d7b-b90f-99410a99133d\n",
      "9d13ef1f-c48c-4d7b-b90f-99410a99133d\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde7ab20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
